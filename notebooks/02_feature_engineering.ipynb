{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02.- Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from utils.plotting import candlestick_plot, local_maxima_minima_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>11610.0</td>\n",
       "      <td>11881.8</td>\n",
       "      <td>11574.4</td>\n",
       "      <td>11846.6</td>\n",
       "      <td>60107000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>11206.6</td>\n",
       "      <td>11530.0</td>\n",
       "      <td>11159.8</td>\n",
       "      <td>11499.5</td>\n",
       "      <td>62539000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>10863.1</td>\n",
       "      <td>11068.1</td>\n",
       "      <td>10824.9</td>\n",
       "      <td>11206.6</td>\n",
       "      <td>68153000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>11102.4</td>\n",
       "      <td>11137.9</td>\n",
       "      <td>10882.7</td>\n",
       "      <td>10963.4</td>\n",
       "      <td>144207000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>11173.3</td>\n",
       "      <td>11364.3</td>\n",
       "      <td>11120.6</td>\n",
       "      <td>11363.8</td>\n",
       "      <td>133817000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              close     high      low     open          vol\n",
       "2000-01-03  11610.0  11881.8  11574.4  11846.6   60107000.0\n",
       "2000-01-04  11206.6  11530.0  11159.8  11499.5   62539000.0\n",
       "2000-01-05  10863.1  11068.1  10824.9  11206.6   68153000.0\n",
       "2000-01-07  11102.4  11137.9  10882.7  10963.4  144207000.0\n",
       "2000-01-10  11173.3  11364.3  11120.6  11363.8  133817000.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the pickle file containing raw benchmark data.\n",
    "with open('../data/raw/benchmark_data.pkl', 'rb') as handle:\n",
    "    bm = pkl.load(handle)\n",
    "\n",
    "data = bm['ibex']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489e335c4ceb4c1ebd5dfbe1eccabb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'close': [6913.0, 6893.6, 6713.4, 6592.2, 6686.6, 7078.4, 7133.8,\n",
       "                        6997.7, 6858.3, 6637.7, 6724.6, 6420.9, 6421.2, 6660.6,\n",
       "                        6751.6, 6420.4, 6251.9, 6158.6, 6004.5, 6310.1, 6303.4,\n",
       "                        6659.8, 6322.3, 6249.3, 6074.9, 6114.1, 5963.2, 6168.6,\n",
       "                        6091.7, 6396.1],\n",
       "              'high': [6933.0, 6999.3, 6837.5, 6807.2, 6717.0, 7078.4, 7165.1,\n",
       "                       7164.6, 6997.4, 6776.0, 6831.9, 6777.2, 6579.6, 6729.4,\n",
       "                       6861.7, 6659.4, 6458.5, 6433.3, 6179.2, 6369.0, 6313.5,\n",
       "                       6659.8, 6743.5, 6507.5, 6364.0, 6146.9, 6176.6, 6220.9,\n",
       "                       6269.0, 6421.7],\n",
       "              'low': [6799.5, 6796.1, 6713.4, 6579.7, 6635.3, 6744.8, 6996.9,\n",
       "                      6927.8, 6838.9, 6631.1, 6633.3, 6408.3, 6271.8, 6379.8,\n",
       "                      6639.6, 6420.4, 6251.9, 6105.8, 5824.2, 6166.5, 6118.4,\n",
       "                      6260.1, 6322.3, 6213.8, 6037.6, 6029.3, 5963.2, 5815.6,\n",
       "                      6058.9, 6172.2],\n",
       "              'open': [6810.3, 6851.4, 6794.2, 6738.7, 6685.6, 6752.6, 7009.8,\n",
       "                       7110.3, 6915.2, 6737.3, 6800.0, 6726.9, 6557.3, 6411.9,\n",
       "                       6703.5, 6659.4, 6374.0, 6309.4, 6074.3, 6365.5, 6239.6,\n",
       "                       6361.9, 6672.8, 6369.0, 6250.4, 6089.4, 6145.4, 5879.4,\n",
       "                       6209.0, 6184.9],\n",
       "              'type': 'candlestick',\n",
       "              'uid': '685d9269-d792-4248-abcd-2a3f1f5760b6',\n",
       "              'x': [2002-06-28 00:00:00, 2002-07-01 00:00:00, 2002-07-02 00:00:00,\n",
       "                    2002-07-03 00:00:00, 2002-07-04 00:00:00, 2002-07-05 00:00:00,\n",
       "                    2002-07-08 00:00:00, 2002-07-09 00:00:00, 2002-07-10 00:00:00,\n",
       "                    2002-07-11 00:00:00, 2002-07-12 00:00:00, 2002-07-15 00:00:00,\n",
       "                    2002-07-16 00:00:00, 2002-07-17 00:00:00, 2002-07-18 00:00:00,\n",
       "                    2002-07-19 00:00:00, 2002-07-22 00:00:00, 2002-07-23 00:00:00,\n",
       "                    2002-07-24 00:00:00, 2002-07-25 00:00:00, 2002-07-26 00:00:00,\n",
       "                    2002-07-29 00:00:00, 2002-07-30 00:00:00, 2002-07-31 00:00:00,\n",
       "                    2002-08-01 00:00:00, 2002-08-02 00:00:00, 2002-08-05 00:00:00,\n",
       "                    2002-08-06 00:00:00, 2002-08-07 00:00:00, 2002-08-08 00:00:00]}],\n",
       "    'layout': {'height': 500,\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Candlestick Chart: Random Window'},\n",
       "               'xaxis': {'rangeslider': {'visible': False}, 'type': 'date'}}\n",
       "})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 30\n",
    "\n",
    "# Randomly select a starting index\n",
    "start_index = np.random.randint(0, len(data) - window_size + 1)\n",
    "\n",
    "# Select the consecutive window of rows\n",
    "random_window = data.iloc[start_index:start_index + window_size]\n",
    "candlestick_plot(random_window, 'Random Window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_min_max(data: pd.DataFrame) -> tuple[pd.Series,\n",
    "                                               np.ndarray,\n",
    "                                               np.ndarray]:\n",
    "    \"\"\"\n",
    "    Identifies local minima and maxima from the 'low' values\n",
    "    of a given time series using polynomial fitting.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): A DataFrame containing a 'low'\n",
    "        column that represents the lowest values (e.g., stock lows).\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.Series, np.ndarray, np.ndarray]: \n",
    "            - A Series of the normalized 'low' values.\n",
    "            - Indices of the local minima.\n",
    "            - Indices of the local maxima.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize the 'low' values of the data using min-max scaling, \n",
    "    # bringing values into the range [0, 1].\n",
    "    data_scaled = pd.Series(\n",
    "        preprocessing.minmax_scale(data['low']),\n",
    "        index=data.index\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Prepare the data for polynomial fitting. 'x_data' are the \n",
    "    # indices and 'y_data' are the scaled 'low' values.\n",
    "    x_data = data_scaled.index.tolist()\n",
    "    y_data = data_scaled\n",
    "\n",
    "    # Create a smooth range for fitting\n",
    "    x = np.linspace(0, max(x_data), max(x_data) + 1)  \n",
    "\n",
    "    # Fit a 15th degree polynomial to the data. This degree captures \n",
    "    # local variations in the data.\n",
    "    pol = np.polyfit(x_data, y_data, 15)\n",
    "    # Evaluate the polynomial at the specified x values\n",
    "    y_pol = np.polyval(pol, x)\n",
    "\n",
    "    # Find local minima (where the second derivative changes \n",
    "    # sign from negative to positive)\n",
    "    local_min = (\n",
    "        np.diff(np.sign(np.diff(y_pol))) > 0\n",
    "        ).nonzero()[0] + 1\n",
    "\n",
    "    # Find local maxima (where the second derivative changes \n",
    "    # sign from positive to negative)\n",
    "    local_max = (\n",
    "        np.diff(np.sign(np.diff(y_pol))) < 0\n",
    "        ).nonzero()[0] + 1\n",
    "\n",
    "    # Return the normalized 'low' values, local minima, and \n",
    "    # local maxima\n",
    "    return data_scaled, local_min, local_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 1: Absolute Extrema Duration\n",
    "This feature could highlight relative compression or elongation of trends. For instance:\n",
    "\n",
    "1. **Rapid Changes**:\n",
    "   A small time difference could hint at erratic or impulsive market behavior, potentially filtering out broader, more gradual trends that might not fit a double-bottom scenario.\n",
    "\n",
    "2. **Structure of Support and Resistance**:\n",
    "   Longer time differences between the extremes could indicate a more stable consolidation, aligning with the characteristics of a well-formed double bottom, where the two lows and the interim peak occur over a longer timeframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_extrema_duration(data: pd.DataFrame) -> float:\n",
    "    \"\"\"Calculate the number of days between the maximum \n",
    "    and minimum values in a time series.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing OHLC data.\n",
    "\n",
    "    Returns:\n",
    "        float: Number of days between the highest and \n",
    "        lowest values divided by the window lengh.\n",
    "        \n",
    "        This normalization can make your model more robust \n",
    "        when handling different time windows or comparing \n",
    "        different patterns\n",
    "    \"\"\"\n",
    "    # Get the indices of the maximum and minimum \n",
    "    # values directly\n",
    "    max_index = data.index.get_loc(\n",
    "        data.high.idxmax().strftime(\"%Y-%m-%d\"))\n",
    "    min_index = data.index.get_loc(\n",
    "        data.low.idxmin().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # Calculate the difference in days directly \n",
    "    # and normalizes the result\n",
    "    duration = abs(\n",
    "        (max_index - min_index)\n",
    "        ) / len(data)\n",
    "    \n",
    "    return duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absolute_extrema_duration(random_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 2: Low Threshold Minima Count\n",
    "\n",
    "1. **Capturing Potential \"Bottoms\"**:\n",
    "   The double-bottom pattern is characterized by two distinct troughs. By counting local minima that fall below a threshold, this feature highlights regions where the price exhibits pronounced dips, which are critical to identifying the pattern.\n",
    "\n",
    "2. **Indicator of Significant Downward Movements**:\n",
    "   A higher count of minima below the threshold suggests strong downward pressures within the window, increasing the likelihood of the presence of one or more \"bottoms.\" This metric helps focus the analysis on windows with sufficient depth for the pattern to exist.\n",
    "\n",
    "3. **Normalization Across Windows**:\n",
    "   Dividing the count by the length of the data window ensures that the feature is scale-invariant and comparable across windows of different sizes. This is essential for ensuring that the feature is meaningful in varying contexts, regardless of the specific duration of the window.\n",
    "\n",
    "4. **Threshold as a Proxy for Pattern Shape**:\n",
    "   The chosen threshold (e.g., 0.20) is a proxy for the depth of price movements. Adjusting this value can help fine-tune the feature to be sensitive to the specific characteristics of double bottoms in the dataset being analyzed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_threshold_minima_count(data: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the proportion of local minima below a specified \n",
    "    threshold within a time window.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing OHLC data.\n",
    "\n",
    "    Returns:\n",
    "        float: Proportion of local minima below the 0.20 \n",
    "        threshold relative to the data length.\n",
    "    \"\"\"\n",
    "    # Scale the 'low' column and find local minima\n",
    "    data_scaled, local_min, _ = local_min_max(data)\n",
    "    \n",
    "    # Extract the values of the local minima\n",
    "    local_min_values = data_scaled.loc[local_min]\n",
    "\n",
    "    # Count minima below the threshold and normalize \n",
    "    # by the data length\n",
    "    count = local_min_values.loc[\n",
    "        (local_min_values < 0.20)].count() / len(data)\n",
    "    \n",
    "    # Return the computed proportion\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_threshold_minima_count(random_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 3: Maxima Between Minima\n",
    "\n",
    "This feature is critical because it analyzes the relationship between two significant minima and the local maxima that might lie between them.\n",
    "\n",
    "1. **Pattern Recognition in Double Bottoms**: \n",
    "   The double-bottom pattern is characterized by two nearly equal lows (minima) separated by a peak (maximum). This feature captures the core structure of this pattern by checking if a maximum exists between two significant, low-valued minima.\n",
    "\n",
    "2. **Validation of Reversal Potential**:\n",
    "   By ensuring the minima are below a specified threshold (e.g., 0.20), the function confirms that these lows are significant enough to suggest potential market exhaustion. If a high lies between these lows, it indicates a potential reversal setup.\n",
    "\n",
    "3. **Highlighting Key Support and Resistance Levels**:\n",
    "   The relationship between the minima and maxima offers insights into market dynamics. The presence of a maximum between two significant lows suggests a potential neckline resistance, which is critical for validating the double-bottom breakout signal.\n",
    "\n",
    "4. **Temporal and Spatial Arrangement**:\n",
    "   This feature ensures that the minima and the intervening maximum occur in the correct sequence, an essential requirement for confirming the double-bottom shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_between_min(data: pd.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    Determines if the first local maximum lies between \n",
    "    the two lowest minima below a specific threshold (0.20),\n",
    "    indicating potential double-bottom behavior.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): A DataFrame containing OHLC data.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the first local maximum is between \n",
    "        the two lowest minima below the threshold, \n",
    "        False otherwise.\n",
    "    \"\"\"\n",
    "    # Identify scaled data, local minima, and maxima\n",
    "    data_scaled, local_minima, local_maxima = local_min_max(data)\n",
    "\n",
    "    # Extract and sort the two lowest minima\n",
    "    lowest_minima = (\n",
    "        data_scaled.loc[local_minima]\n",
    "        .sort_values()\n",
    "        .iloc[:2]\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    # Extract sorted maxima for comparison\n",
    "    sorted_maxima = data_scaled.loc[\n",
    "        local_maxima].sort_values()\n",
    "\n",
    "    # Check conditions: exactly two minima and both \n",
    "    # below the threshold\n",
    "    if (\n",
    "        len(lowest_minima) == 2 and \n",
    "        (lowest_minima.iloc[0] < 0.20) and \n",
    "        (lowest_minima.iloc[1] < 0.20)\n",
    "    ):\n",
    "        # Verify if the first local maximum is between \n",
    "        # the two minima\n",
    "        return any(\n",
    "            lowest_minima.index[0] < max_idx < lowest_minima.index[1]\n",
    "            for max_idx in sorted_maxima.index\n",
    "        )\n",
    "\n",
    "    # Return False if conditions are not met\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_between_min(random_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 4: Pattern Extrema Duration\n",
    "\n",
    "1. **Accurate Temporal Relationship Between Extremes**:\n",
    "   The duration between the minima and maxima within a potential Double Bottom is critical for understanding the timing of the pattern's formation. A shorter duration between the minima and maxima could suggest a tight price action, potentially indicating a quick reversal or confirmation of the pattern. On the other hand, a longer duration may imply a slower development but could still be indicative of a valid reversal. This feature provides a time window that refines the model's ability to distinguish between a valid Double Bottom and other similar patterns.\n",
    "\n",
    "2. **Supports the Continuity of the Price Action**:\n",
    "   Even though the Polyfit method handles noise, the duration of the pattern captures how the market moves between key points. A short duration between the local minimum and maximum might indicate a swift bounce after a fall, which is characteristic of some strong reversals. This feature helps the model understand how quickly or slowly the market can form a valid reversal, aligning with the characteristic behavior of Double Bottoms, where price typically drops, forms a bottom, rises, and revisits that bottom before reversing upwards.\n",
    "\n",
    "3. **Model’s Temporal Sensitivity to Pattern Development**:\n",
    "   This feature fine-tunes the model’s ability to learn from historical instances of Double Bottoms with similar timing structures. It helps ensure that the model recognizes patterns that form over reasonable periods as valid instances. By leveraging this feature, the model is equipped to make decisions about the timing and context of potential Double Bottoms in future data, which is essential for trading decisions or trend predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_extrema_duration(data: pd.DataFrame) -> float:\n",
    "    \"\"\"Calculate the duration between the potential \n",
    "    minima and maxima of a Double Bottom pattern.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): A DataFrame containing OHLC data.\n",
    "\n",
    "    Returns:\n",
    "        float: The duration (in days, relative to the \n",
    "        window length) between the closest local minimum \n",
    "        and local maximum forming the potential pattern.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the scaled data and the indices of the local minima and maxima\n",
    "    data_scaled, local_minima, local_maxima = local_min_max(data)\n",
    "\n",
    "    # Get the indices of the closest local minimum \n",
    "    # and maximum that form the potential Double Bottom \n",
    "    # pattern\n",
    "    min_index = data_scaled.loc[\n",
    "        local_minima].sort_values().iloc[0:1].index\n",
    "    max_index = data_scaled.loc[\n",
    "        local_maxima].sort_values().iloc[0:1].index\n",
    "\n",
    "    # Calculate the duration in days between the \n",
    "    # local minimum and maximum indices, normalized \n",
    "    # by the length of the data\n",
    "    days_between = abs(\n",
    "        max_index - min_index\n",
    "        ) / len(data)\n",
    "\n",
    "    return days_between.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.16666666666666666)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_extrema_duration(random_window)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "double-bottom-detection-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
